{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Stap 1"
      ],
      "metadata": {
        "id": "YvmILFZVkn_f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JKvbSew_jJmv"
      },
      "outputs": [],
      "source": [
        "text = open(\"Original.txt\").read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2NmmwUxkAyN",
        "outputId": "1e12fc17-fccf-4910-f9e5-116a9a8b459c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, generate, and interact with human language. It combines linguistics, computer science, and machine learning to bridge the communication gap between humans and machines. Today, NLP powers many of the tools we use daily, from voice assistants and chatbots to translation systems and search engines.\n",
            "\n",
            "At its core, NLP involves breaking down language into smaller, analyzable components. This begins with tokenization, the process of dividing text into words or subword units. After tokenization, the system can apply methods such as part-of-speech tagging to label each word with its grammatical role (noun, verb, adjective, etc.). Another step is syntactic parsing, which reveals the structure of a sentence and helps determine how words relate to each other. These foundational processes allow NLP systems to extract meaning and patterns from large volumes of text.\n",
            "\n",
            "A major challenge in NLP is that human language is ambiguous and context-dependent. Words can have multiple meanings, and sentences can be understood differently based on tone, culture, or previous statements. To address this complexity, modern NLP relies heavily on machine learning, especially deep learning. Models such as Word2Vec and GloVe introduced the concept of word embeddings, where words are represented as dense vectors in a continuous space. This allows algorithms to capture semantic relationships—for example, “king” and “queen” are close in vector space.\n",
            "\n",
            "In recent years, the introduction of transformer-based models has revolutionized NLP. Transformers use attention mechanisms to focus on different parts of a sentence, enabling them to understand long-range dependencies and context more effectively. Models such as BERT, GPT, and T5 can perform tasks like question answering, summarization, translation, and dialogue generation at a level that often rivals human performance. These large language models are trained on massive datasets, giving them the ability to learn complex patterns and produce coherent, context-aware text.\n",
            "\n",
            "NLP has countless applications across industries. In customer service, chatbots and virtual assistants help automate interactions, reduce workload, and provide instant responses. In healthcare, NLP systems extract important information from medical records to support diagnosis and research. In finance, text analysis tools detect fraudulent transactions or analyze market sentiment. Even in education, NLP supports automated essay scoring, grammar correction, and personalized learning tools.\n",
            "\n",
            "Despite its progress, NLP still faces several challenges. Understanding sarcasm, emotion, cultural references, and domain-specific jargon remains difficult. Bias in training data can also lead to unfair or inaccurate results. Researchers continue to work on improving fairness, interpretability, and the ability of systems to reason more like humans.\n",
            "\n",
            "Overall, NLP is a rapidly evolving field that plays a central role in modern AI. As models become more advanced and data becomes more abundant, NLP will continue to shape the future of communication and digital interaction, making technology more intuitive, responsive, and human-centered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1kHsSkakTWB",
        "outputId": "2ae84383-7926-45c7-e87b-78d6debb9fa1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3287"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVwMXsKTkar9",
        "outputId": "95ff33cf-4cab-403d-c15a-2b6660696d87"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "468"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "2PcgJ9rcktek"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRw-I17qkxTO",
        "outputId": "20a6899f-99f6-438d-9f29-bb0f3e548eba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stap 2"
      ],
      "metadata": {
        "id": "rlJ3RR7PnC30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Verwerk de tekst met spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Zinnen extraheren\n",
        "sentences = [sent.text.strip() for sent in doc.sents]\n",
        "print(\"Aantal zinnen:\", len(sentences))\n",
        "print(\"\\nVoorbeeldzinnen:\\n\")\n",
        "for s in sentences[:3]:\n",
        "    print(\"-\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw6MCeKpk35Z",
        "outputId": "eea12070-b9fa-4a5f-dd68-1c54bbc719c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aantal zinnen: 28\n",
            "\n",
            "Voorbeeldzinnen:\n",
            "\n",
            "- Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, generate, and interact with human language.\n",
            "- It combines linguistics, computer science, and machine learning to bridge the communication gap between humans and machines.\n",
            "- Today, NLP powers many of the tools we use daily, from voice assistants and chatbots to translation systems and search engines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pro(sen):\n",
        "  doc = nlp(sen.lower())\n",
        "\n",
        "  tokens = [token.text for token in doc\n",
        "            if not token.is_stop and not token.is_punct]\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "kWc_j3lplZSV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_sentences = [pro(s) for s in sentences]"
      ],
      "metadata": {
        "id": "2O1bFT7GmMg1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in process_sentences[:3]:\n",
        "  print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAevBndLmoZ9",
        "outputId": "e542f7f9-cb6e-4679-8cde-5d5aacffc3c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', 'nlp', 'field', 'artificial', 'intelligence', 'focuses', 'enabling', 'computers', 'understand', 'interpret', 'generate', 'interact', 'human', 'language']\n",
            "['combines', 'linguistics', 'computer', 'science', 'machine', 'learning', 'bridge', 'communication', 'gap', 'humans', 'machines']\n",
            "['today', 'nlp', 'powers', 'tools', 'use', 'daily', 'voice', 'assistants', 'chatbots', 'translation', 'systems', 'search', 'engines']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stap 3"
      ],
      "metadata": {
        "id": "NwhtFT6DnEzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "vec_tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "G0kmiePEnAGr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = vec_tfidf.fit_transform(sentences)"
      ],
      "metadata": {
        "id": "JSZJmAMOnWRr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKOiXa_VnfdK",
        "outputId": "479c3fcb-b243-494b-8581-aed04b38450d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 454 stored elements and shape (28, 295)>\n",
            "  Coords\tValues\n",
            "  (0, 176)\t0.2407816104137743\n",
            "  (0, 151)\t0.36146685071344836\n",
            "  (0, 197)\t0.2407816104137743\n",
            "  (0, 177)\t0.11325835969195693\n",
            "  (0, 145)\t0.18073342535672418\n",
            "  (0, 101)\t0.2142098652253707\n",
            "  (0, 179)\t0.12336046836439145\n",
            "  (0, 22)\t0.2407816104137743\n",
            "  (0, 134)\t0.2407816104137743\n",
            "  (0, 256)\t0.18073342535672418\n",
            "  (0, 104)\t0.2407816104137743\n",
            "  (0, 181)\t0.15868305812244657\n",
            "  (0, 90)\t0.2142098652253707\n",
            "  (0, 55)\t0.2407816104137743\n",
            "  (0, 261)\t0.10873698173783097\n",
            "  (0, 272)\t0.2142098652253707\n",
            "  (0, 138)\t0.2407816104137743\n",
            "  (0, 111)\t0.2407816104137743\n",
            "  (0, 16)\t0.09324548259150939\n",
            "  (0, 135)\t0.2407816104137743\n",
            "  (0, 288)\t0.19535691198328467\n",
            "  (0, 125)\t0.18073342535672418\n",
            "  (1, 261)\t0.12465905315473613\n",
            "  (1, 16)\t0.21379834873179843\n",
            "  (1, 146)\t0.27603863093811487\n",
            "  :\t:\n",
            "  (27, 179)\t0.10001271167679798\n",
            "  (27, 261)\t0.08815693185459789\n",
            "  (27, 16)\t0.22679227039025482\n",
            "  (27, 125)\t0.14652700496539098\n",
            "  (27, 257)\t0.10463568967253183\n",
            "  (27, 50)\t0.17366754336427925\n",
            "  (27, 23)\t0.14652700496539098\n",
            "  (27, 172)\t0.13684012752053862\n",
            "  (27, 174)\t0.4751483543627732\n",
            "  (27, 67)\t0.17366754336427925\n",
            "  (27, 58)\t0.17366754336427925\n",
            "  (27, 32)\t0.19521020063133174\n",
            "  (27, 5)\t0.19521020063133174\n",
            "  (27, 33)\t0.19521020063133174\n",
            "  (27, 1)\t0.19521020063133174\n",
            "  (27, 287)\t0.19521020063133174\n",
            "  (27, 234)\t0.19521020063133174\n",
            "  (27, 109)\t0.19521020063133174\n",
            "  (27, 81)\t0.19521020063133174\n",
            "  (27, 136)\t0.19521020063133174\n",
            "  (27, 163)\t0.19521020063133174\n",
            "  (27, 254)\t0.19521020063133174\n",
            "  (27, 143)\t0.19521020063133174\n",
            "  (27, 218)\t0.19521020063133174\n",
            "  (27, 42)\t0.19521020063133174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen_score = matrix.sum(axis=1).A1"
      ],
      "metadata": {
        "id": "H2dxiasOnoMK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sen_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c5cWth5n23n",
        "outputId": "ab202768-3da5-4299-9893-cb28defcd3b1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.50597248 3.93145674 4.3614043  3.41451853 3.67499576 4.9153446\n",
            " 4.34473006 3.86430424 3.27228938 4.01529652 3.44312664 4.41953\n",
            " 4.01489109 3.34352527 4.50327483 4.86430362 4.68710268 2.39403096\n",
            " 3.8390143  3.72877795 3.41826663 3.62717181 2.77622443 3.26038329\n",
            " 3.38336826 4.01950359 3.53260392 4.77040811]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sort_score = np.argsort(sen_score)[::-1]"
      ],
      "metadata": {
        "id": "M1cbBU1GoDyT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sort_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je1P6DxcoN0C",
        "outputId": "ff28b8c1-11d2-4f2d-c973-c37f4e31569b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5 15 27 16  0 14 11  2  6 25  9 12  1  7 18 19  4 21 26 10 20  3 24 13\n",
            "  8 23 22 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary = [sentences[i] for i in sort_score[:1]]\n",
        "\n",
        "for s in summary:\n",
        "  print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "535G40z9ornZ",
        "outputId": "c9ac2bd6-1093-42c2-ea76-0bf5f834b31e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After tokenization, the system can apply methods such as part-of-speech tagging to label each word with its grammatical role (noun, verb, adjective, etc.).\n"
          ]
        }
      ]
    }
  ]
}