{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b224f2",
   "metadata": {},
   "source": [
    "Why Vectors?\n",
    "\n",
    "Computers can’t understand raw text, they work with numbers.\n",
    "Each word or document must be converted into numerical form (a vector) so that algorithms (e.g., classifiers, clustering, sentiment analysis) can process them.\n",
    "\n",
    "Vectorization = mapping text → numerical representation.\n",
    "Example:\n",
    "“I love NLP” → [0.4, 0.9, 0.1] (a simplified vector form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe81c2",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "BoW just counts, but it doesn’t know which words are important.\n",
    "For example, words like “the” or “I” appear often everywhere, so they’re not useful.\n",
    "\n",
    "TF-IDF gives:\n",
    "\n",
    "- High weight to rare, important words\n",
    "- Low weight to common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab2bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['and' 'eat' 'going' 'hate' 'love' 'out' 'something' 'to']\n",
      "BoW Vectors:\n",
      " [[0 1 1 0 1 1 0 1]\n",
      " [1 1 0 1 1 0 1 1]]\n",
      "\n",
      "Vocabulary: ['and' 'eat' 'going' 'hate' 'love' 'out' 'something' 'to']\n",
      "TF-IDF Vectors:\n",
      " [[0.         0.37930349 0.53309782 0.         0.37930349 0.53309782\n",
      "  0.         0.37930349]\n",
      " [0.47042643 0.33471228 0.         0.47042643 0.33471228 0.\n",
      "  0.47042643 0.33471228]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "texts = [\"I love going out to eat\", \"I hate and love something I eat to\"]\n",
    "\n",
    "# --- Bag-of-Words ---\n",
    "bow = CountVectorizer()\n",
    "bow_vectors = bow.fit_transform(texts)\n",
    "\n",
    "print(\"Vocabulary:\", bow.get_feature_names_out())\n",
    "print(\"BoW Vectors:\\n\", bow_vectors.toarray())\n",
    "\n",
    "# --- TF-IDF ---\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf.fit_transform(texts)\n",
    "\n",
    "print(\"\\nVocabulary:\", tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF Vectors:\\n\", tfidf_vectors.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad283d6",
   "metadata": {},
   "source": [
    "Wat is het doel van TF-IDF?\n",
    "\n",
    "Bij Bag-of-Words (BoW) tel je alleen hoe vaak een woord voorkomt.\n",
    "Maar dat heeft één groot probleem:\n",
    "\n",
    "Veel voorkomende woorden zoals “de”, “het”, “en”, “is”, komen in bijna alle teksten voor,\n",
    "dus ze zeggen niets unieks over een document.\n",
    "\n",
    "TF-IDF lost dat op door:\n",
    "\n",
    "-Woorden die vaak voorkomen in één tekst → hogere score te geven (TF)\n",
    "-Woorden die in bijna alle teksten voorkomen → lagere score te geven (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33732c1a",
   "metadata": {},
   "source": [
    "TF-IDF bestaat uit 2 delen\n",
    "\n",
    "TF (Term Frequency)\n",
    "Hoe vaak komt een woord t voor in document d\n",
    "\n",
    "TF(t,d) = (aantal keer dat t voorkomt in d)/(totaal aantal woorden in d)\n",
    "\n",
    "\n",
    "\n",
    "IDF (Inverse Document Frequency)\n",
    "\n",
    "Hoe zeldzaam is dat woord in de hele collectie?\n",
    "\n",
    "IDF(t) = log (N/DF(t))\n",
    "\n",
    "\n",
    "waarbij:\n",
    "- N = totaal aantal documenten\n",
    "- DF(t) = aantal documenten waarin het woord voorkomt\n",
    "\n",
    "TF-IDF = TF x IDF\n",
    "\n",
    "##############################################################\n",
    "\n",
    "\n",
    "Stel we hebben 3 documenten:\n",
    "\n",
    "\n",
    "\n",
    "| Document | Tekst                     |\n",
    "| -------- | ------------------------- |\n",
    "| D1       | \"I love NLP\"              |\n",
    "| D2       | \"I love Machine Learning\" |\n",
    "| D3       | \"I hate NLP\"              |\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "Bereken TF\n",
    "\n",
    "| Woord    | D1 | D2 | D3 |\n",
    "| -------- | -- | -- | -- |\n",
    "| I        | 1  | 1  | 1  |\n",
    "| love     | 1  | 1  | 0  |\n",
    "| hate     | 0  | 0  | 1  |\n",
    "| NLP      | 1  | 0  | 1  |\n",
    "| Machine  | 0  | 1  | 0  |\n",
    "| Learning | 0  | 1  | 0  |\n",
    "\n",
    "\n",
    "(we doen hier alsof elk document even lang is, dus TF = gewoon de telling)\n",
    "\n",
    "################################################################\n",
    "\n",
    "| Woord    | In hoeveel documenten komt het voor? | DF |\n",
    "| -------- | ------------------------------------ | -- |\n",
    "| I        | 3                                    | 3  |\n",
    "| love     | 2                                    | 2  |\n",
    "| hate     | 1                                    | 1  |\n",
    "| NLP      | 2                                    | 2  |\n",
    "| Machine  | 1                                    | 1  |\n",
    "| Learning | 1                                    | 1  |\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "Berekenen van IDF\n",
    "\n",
    "IDF = log (N / DF(t))\n",
    "\n",
    "\n",
    "| Woord    | DF | IDF = log(3/DF)  |\n",
    "| -------- | -- | ---------------- |\n",
    "| I        | 3  | log(1) = 0       |\n",
    "| love     | 2  | log(1.5) ≈ 0.176 |\n",
    "| hate     | 1  | log(3) ≈ 0.477   |\n",
    "| NLP      | 2  | log(1.5) ≈ 0.176 |\n",
    "| Machine  | 1  | log(3) ≈ 0.477   |\n",
    "| Learning | 1  | log(3) ≈ 0.477   |\n",
    "\n",
    "\n",
    "\n",
    "################################################################\n",
    "\n",
    "Bereken TF-IDF\n",
    "\n",
    "Voor elk woord in elk document:\n",
    "| Woord    | D1    | D2    | D3    |\n",
    "| -------- | ----- | ----- | ----- |\n",
    "| I        | 0     | 0     | 0     |\n",
    "| love     | 0.176 | 0.176 | 0     |\n",
    "| hate     | 0     | 0     | 0.477 |\n",
    "| NLP      | 0.176 | 0     | 0.176 |\n",
    "| Machine  | 0     | 0.477 | 0     |\n",
    "| Learning | 0     | 0.477 | 0     |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
