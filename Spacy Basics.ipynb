{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f96061",
   "metadata": {},
   "source": [
    "Install spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35eb4df",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e11d4",
   "metadata": {},
   "source": [
    "Import spaCy & Load a Language Model\n",
    "The model includes vocabulary, syntax, and named entity recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cea5a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ada2e4",
   "metadata": {},
   "source": [
    "Splitting text into words, punctuation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea5b6a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy\n",
      "is\n",
      "an\n",
      "amazing\n",
      "NLP\n",
      "library\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"SpaCy is an amazing NLP library!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62787ed5",
   "metadata": {},
   "source": [
    "Part-of-Speech (POS) Tagging\n",
    "\n",
    "Identifying the grammatical role of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267c3d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy -> PROPN\n",
      "is -> AUX\n",
      "an -> DET\n",
      "amazing -> ADJ\n",
      "NLP -> PROPN\n",
      "library -> NOUN\n",
      "! -> PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.pos_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eaf5ae",
   "metadata": {},
   "source": [
    "ðŸ§ Named Entity Recognition (NER)\n",
    "\n",
    "Finds names, places, dates, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57e3d2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jennifer Simons -> PERSON\n",
      "first -> ORDINAL\n",
      "2025 -> DATE\n",
      "KFC -> ORG\n",
      "Lelydorp -> GPE\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Jennifer Simons becomes the first female president in 2025 and she will open a new KFC restaurant in Lelydorp\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} -> {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abe447",
   "metadata": {},
   "source": [
    "Lemmatization\n",
    "\n",
    "Finds the base form of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707c510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The -> the\n",
      "cats -> cat\n",
      "are -> be\n",
      "eating -> eat\n",
      "the -> the\n",
      "dogs -> dog\n",
      ". -> .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The cats are eating the dogs.\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6920d",
   "metadata": {},
   "source": [
    "Custom Pipeline Component\n",
    "\n",
    "You can create your own function to process text inside spaCyâ€™s pipeline.\n",
    "SpaCy pipelines process text through multiple stages â€” tokenization, tagging, parsing, NER, etc.\n",
    "You can add custom stages to modify or analyze text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e4f975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc length: 7\n"
     ]
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_component\")\n",
    "def custom_component(doc):\n",
    "    print(\"Doc length:\", len(doc))\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"custom_component\", last=True)\n",
    "\n",
    "doc = nlp(\"This is a custom component example.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
